import os, re, base64, textwrap
from typing import List, Dict, Any

import streamlit as st
from dotenv import load_dotenv

from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from openai import AzureOpenAI

# ---------- ì´ˆê¸° ì„¤ì • ----------
st.set_page_config(page_title="HRWikiBot â€“ UI", layout="wide")
load_dotenv()

SEARCH_ENDPOINT = os.getenv("SEARCH_ENDPOINT")
SEARCH_API_KEY = os.getenv("SEARCH_API_KEY")
INDEX_NAME = os.getenv("INDEX_NAME")

AOAI_ENDPOINT = os.getenv("AOAI_ENDPOINT")
AOAI_KEY = (
    os.getenv("AOAI_KEY")
    or os.getenv("AZURE_OPENAI_API_KEY")
    or os.getenv("OPENAI_API_KEY")
)
AOAI_VERSION = (
    os.getenv("AOAI_VERSION") or os.getenv("OPENAI_API_VERSION") or "2024-02-15-preview"
)
AOAI_DEPLOYMENT = os.getenv("AOAI_DEPLOYMENT") or "gpt-4o-mini"

REQUIRED = {
    "SEARCH_ENDPOINT": SEARCH_ENDPOINT,
    "SEARCH_API_KEY": SEARCH_API_KEY,
    "INDEX_NAME": INDEX_NAME,
    "AOAI_ENDPOINT": AOAI_ENDPOINT,
    "AOAI_KEY": AOAI_KEY,
    "AOAI_VERSION": AOAI_VERSION,
    "AOAI_DEPLOYMENT": AOAI_DEPLOYMENT,
}
missing = [k for k, v in REQUIRED.items() if not v]

top_k = 2
use_highlight = False
use_semantic = False
sem_config = None
max_ctx = 1000
temperature = 0.7


APP_TITLE = "ì‚¬ë‚´ ê°€ì´ë“œë¶ ì±—ë´‡"
CATEGORIES = [
    "HR/ì¸ì‚¬",
    "ê·¼ë¡œì‹œê°„Â·íœ´ê°€",
    "ê¸‰ì—¬Â·ë³µë¦¬í›„ìƒ",
    "ê²½ì¡°ì‚¬ ì§€ì›",
    "êµìœ¡Â·ì˜¨ë³´ë”©",
    "ì—…ë¬´ í”„ë¡œì„¸ìŠ¤",
    "ì•ˆì „Â·ìœ¤ë¦¬Â·ì¤€ë²•",
    "FAQ",
]

st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ—‚ï¸", layout="wide")

# ---------- ì‚¬ì´ë“œë°” ----------
with st.sidebar:
    st.title("ì¹´í…Œê³ ë¦¬")

    for cat in CATEGORIES:
        st.subheader("- " + cat)
    st.markdown("---")
    top_k = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ (Top-K)", 1, 8, 3)

    # ---------- í‘¸í„° ----------
    st.markdown(
        """
        <style>
        .footer {position: fixed;left: 0;bottom: 0;width: 100%;background-color: #f5f5f5;color: gray;text-align: center;padding: 8px;font-size: 13px;border-top: 1px solid #ddd; z-index:9999}
        </style>
        <div class="footer">
            Â© 2025 HRWikiBot | ë‚´ë¶€ìš© ìƒë‹´ ì„œë¹„ìŠ¤
        </div>
    """,
        unsafe_allow_html=True,
    )


# ---------- í´ë¼ì´ì–¸íŠ¸ (ìºì‹œ) ----------
@st.cache_resource(show_spinner=False)
def get_clients():
    if missing:
        return None, None
    sc = SearchClient(
        endpoint=SEARCH_ENDPOINT,
        index_name=INDEX_NAME,
        credential=AzureKeyCredential(SEARCH_API_KEY),
    )
    ao = AzureOpenAI(
        api_key=AOAI_KEY,
        azure_endpoint=AOAI_ENDPOINT,
        api_version=AOAI_VERSION,
    )
    return sc, ao


search_client, aoai_client = get_clients()

# ---------- ìœ í‹¸ ----------
SEARCH_FIELDS = ["merged_content", "content", "text", "layoutText", "translated_text"]
SELECT_FIELDS = [
    "metadata_storage_name",
    "metadata_storage_path",
    "metadata_storage_last_modified",
    "merged_content",
    "content",
    "text",
    "layoutText",
    "translated_text",
]


def clean_text(t: str, max_len=1000) -> str:
    if not isinstance(t, str):
        return ""
    t = re.sub(r"\s+", " ", t).strip()
    return (t[:max_len] + "â€¦") if len(t) > max_len else t


def pick_body(d: Dict[str, Any]) -> str:
    for k in SEARCH_FIELDS:
        v = d.get(k)
        if isinstance(v, str) and v.strip():
            return v
    return ""


def decode_blob_path(p: str) -> str:
    try:
        return base64.b64decode(p).decode("utf-8")
    except Exception:
        return p or ""


def do_search(query: str, k: int) -> List[Dict[str, Any]]:
    if not search_client:
        return []
    kwargs = dict(
        search_text=query,
        select=SELECT_FIELDS,
        top=k,
        search_fields=SEARCH_FIELDS,  # ë¦¬ìŠ¤íŠ¸!
        include_total_count=True,
    )
    if use_highlight:
        kwargs.update(
            {
                "highlight_fields": ",".join(SEARCH_FIELDS),  # ë¬¸ìì—´(ì½¤ë§ˆ)!
                "highlight_pre_tag": "<mark>",
                "highlight_post_tag": "</mark>",
            }
        )
    if use_semantic:
        kwargs.update({"query_type": "semantic", "semantic_configuration": sem_config})

    return list(search_client.search(**kwargs))


def build_context(docs: List[Dict[str, Any]], limit_chars: int) -> str:
    total = 0
    blocks = []
    for i, d in enumerate(docs, 1):
        hl = d.get("@search.highlights") or {}
        if hl:
            snips = []
            for _, arr in hl.items():
                snips.extend(arr[:2])
            snippet = clean_text(" â€¦ ".join(snips), 1600)
        else:
            snippet = clean_text(pick_body(d), 1600)
        if not snippet:
            continue
        if total + len(snippet) > limit_chars:
            break
        total += len(snippet)
        name = d.get("metadata_storage_name") or f"doc-{i}"
        blocks.append(f"[{i}] {name}\n{snippet}")
    return "\n\n---\n\n".join(blocks)


def ask_rag(query: str, docs: List[Dict[str, Any]]) -> str:
    ctx = build_context(docs, max_ctx)
    if not ctx:
        return "ê´€ë ¨ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ë¥´ê²Œ í•´ë³´ê±°ë‚˜ ì¸ë±ìŠ¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
    sys_prompt = textwrap.dedent(
        """\
        ë‹¹ì‹ ì€ HR ê·œì • ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œ ë°œì·Œë¥¼ ê·¼ê±°ë¡œ
        ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•˜ì„¸ìš”.
        ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ê³ , ì¶”ì¸¡ì€ í”¼í•˜ì„¸ìš”.
        ë‹µë³€ ëì— ì°¸ê³ í•œ ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ëŒ€ê´„í˜¸ë¡œ í‘œê¸°í•˜ì„¸ìš”. ì˜ˆ: [1][2]
    """
    ).strip()
    user_prompt = f"# ë¬¸ì„œ ë°œì·Œ\n{ctx}\n\n# ì§ˆë¬¸\n{query}"
    resp = aoai_client.chat.completions.create(
        model=AOAI_DEPLOYMENT,  # ë°°í¬ ì´ë¦„
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature=temperature,
    )
    return resp.choices[0].message.content


# ---- ì»¨í…ì¸  2ë‹¨ ë ˆì´ì•„ì›ƒ
main, right = st.columns([0.66, 0.36], gap="large")
# ---------- UI ----------
# Main
with main:
    st.title("ğŸ—‚ï¸ HRWikiBot â€“ ì‹ ì…ì‚¬ì›ì„ ìœ„í•œ HR,ê·œì •, ë³µì§€ ì±—ë´‡ ")

    q = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        "ì•„ê¸°ë¥¼ ì„ì‹ í–ˆì–´ìš” ì„ì‹ ê³¼ ì¶œì‚° ê´€ë ¨ ë³µì§€ê°€ ìˆë‚˜ìš”?",
    )

    btn_search = st.button("ê²€ìƒ‰")


if (btn_search) and missing:
    st.stop()

if btn_search:
    try:
        with st.spinner("ê²€ìƒ‰ ì¤‘â€¦"):
            docs = do_search(q, top_k)

        # LAG ëª¨ë¸ ë‹µë³€ ìƒì„±
        with st.spinner("ëª¨ë¸ì´ ë‹µë³€ì„ ìƒì„± ì¤‘â€¦"):
            answer = ask_rag(q, docs)
        st.subheader("ğŸ’¬ ë‹µë³€")
        st.markdown(answer)

        st.subheader(f"ê²€ìƒ‰ ê²°ê³¼ ({len(docs)}ê±´)")

        # ì°¸ê³  ë¬¸ì„œ ê°„ë‹¨ ì¶œë ¥
        refs = []
        for i, d in enumerate(docs[:5], 1):
            p = decode_blob_path(d.get("metadata_storage_path"))
            refs.append(f"[{i}] {d.get('metadata_storage_name')}  |  {p}")
        if refs:
            st.markdown("**ì°¸ê³  ë¬¸ì„œ:**\n" + "\n".join(refs))

        if not docs:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë°”ê¿”ë³´ê±°ë‚˜ ì¸ë±ìŠ¤ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        for i, d in enumerate(docs, 1):
            fname = d.get("metadata_storage_name")
            lm = d.get("metadata_storage_last_modified")
            path = decode_blob_path(d.get("metadata_storage_path"))
            with st.expander(f"[{i}] {fname}  |  {lm}", expanded=(i == 1)):
                if use_highlight and d.get("@search.highlights"):
                    st.markdown("**í•˜ì´ë¼ì´íŠ¸**")
                    for f, snips in d["@search.highlights"].items():
                        st.markdown(
                            f"- *{f}*: " + " â€¦ ".join(snips[:2]), unsafe_allow_html=True
                        )
                else:
                    st.markdown(clean_text(pick_body(d), 500))
                if path:
                    st.markdown(f"[ì›ë¬¸ ì—´ê¸°]({path})")

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: {e}")
        st.exception(e)


# Right panel
with right:
    st.subheader("ë³´ì¡° ì •ë³´")
    tabs = st.tabs(["ğŸ“‚ ê´€ë ¨ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°", "ğŸ“Š ì¸ê¸° FAQ TOP5", "ğŸ“ ì‹ ì… ì²´í¬ë¦¬ìŠ¤íŠ¸"])
    with tabs[0]:
        st.info("ê²€ìƒ‰ í›„ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
        # if st.session_state.last_hits:
        #    h0 = st.session_state.last_hits[0]
        #    st.markdown(f"**{h0['title']}**")
        #    st.code(
        #        h0["content"][:500] + ("â€¦" if len(h0["content"]) > 500 else ""),
        #        language="text",
        #    )
        #    st.caption(f"ì¶œì²˜: {h0['source']}")
        # else:
        #    st.info("ê²€ìƒ‰ í›„ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    with tabs[1]:
        st.info("ê²€ìƒ‰ í›„ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
        # for i, item in enumerate(st.session_state.faq, start=1):
        #    st.markdown(f"{i}. {item}")
    with tabs[2]:
        for it in [
            "ì‚¬ë²ˆ ë°œê¸‰ ë° HR ë“±ë¡",
            "ì „ìê²°ì¬ ê³„ì • ìƒì„±",
            "ì˜¤ë¦¬ì—”í…Œì´ì…˜ ì°¸ì„",
            "ë³´ì•ˆ/ìœ¤ë¦¬ êµìœ¡ ì´ìˆ˜",
            "ë³µì§€ëª° ê³„ì • í™œì„±í™”",
        ]:
            st.checkbox(it, value=False)
